## 常识问题
1. 什么是Apache Kafka?
    - Apache Kafka是一个发布订阅开源消息代理应用程序。这个消息传递应
用程序是用“scala”编码的。基本上，这个项目是由Apache软件启动的。Kafka的设计模式主要基于事务日志设计。

2. Kafka中有哪几个组件?
    - 主题：Kafka主题是一堆或一组消息。
    - 生产者：在Kafka，生产者发布通信以及向Kafka主题发布消息。
    - 消费者：Kafka消费者订阅了一个主题，并且还从主题中读取和处理消息
    - broker：在管理主题中的消息存储时，我们使用Kafka Brokers

14. 什么是消费者组？
    - 消费者组的概念是Apache Kafka独有的。基本上，每个Kafka消费群体都由一个或多个共同消费一组订阅主题的消费者组成

16. Kafka的主要API有哪些
    - Apache Kafka有4个主要API：
       -生产者API
       - 消费者API
       - 流 API
       - 连接器API


18. 在生产者中，何时发生QueueFullException
    - 每当Kafka生产者试图以代理的身份在当时无法处理的速度发送消息时，通常都会发生QueueFullException。但是，为了协作处理增加的负载，用户需要添加足够的代理，因为生产者不会阻止
19. 你能用Kafka做什么？
    - 为了在两个系统之间传输数据，我们可以用它构建实时的数据流管道
    - 另外，我们可以用Kafka构建一个实时流处理平台，它可以对数据快速做出反应


21. 解释Kafka可以接收的消息最大为多少
    - Kafka可以接收的最大消息大小约为1000000字节
22. 传统的消息传递方法有哪些类型
    - 排队：这是一种消费者池可以从服务器读取消息并且每条消息转到其中一个消息的方法
    - 发布-订阅：在发布-订阅中，消息被广播给所有消费者
23. 解释多租户是什么
    - 我们可以轻松地将Kafka部署为多租户解决方案。但是，通过配置主题可以生成或使用数据，可以启用多租户。此外，它还为配额提供操作支持
    - [kafka配额研究](https://www.jianshu.com/p/2dda6d98cdfa)
    - 当Kafka检测到配额透支情况发生时，broker不会返回错误而是直接将超支配额的客户端进行减速处理。它会计算需要X然后令client强制sleep直至令其降到配额之下
    - 目前Kafka支持两大类配额管理:网络带宽（network bandwidth）配额管理，和CPU配额管理
24. 解释流API的作用
    - 一种允许应用程序充当流处理器的API，它还使用一个或多个主题的输入流，并生成一个输出流到一个或多个输出主题，此外，有效地将输入流转换为输出流，我们称之为流API
25. 连接器API的作用是什么
    - 一个允许运行和构建可重用的生产者或消费者的API，将Kafka主题连接到现有的应用程序或数据系统，我们称之为连接器API
26. 比较RabbitMQ与Apache Kafka
    - 功能。Kafka是分布式的、持久的和高度可用的，这里共享和复制数据。RabbitMQ中没有此类功能
    - 性能速度。Apache Kafka–达到每秒100000条消息。RabbitMQ–每秒20000条消息
27. 比较传统队列系统与Apache Kafka
    - 消息保留。传统的队列系统 - 它通常从队列末尾处理完成后删除消息。Apache Kafka中，消息即使在处理后仍然存在。这意味着Kafka中的消息不会因消费者收到消息而被删除
    - Kafka 支持实时的流式处理
    - 支持消息持久化&过期
    - 支持高可用&分布式
28. 解释如何调整Kafka以获得最佳性能
    - 调优Apache Kafka的方法是调优它的几个组件
    - 调整Kafka生产者
    - Kafka代理调优
    - 调整Kafka消费者
    - 参考《Kafka权威指南》第6章--可靠性传递中的一些参数调优
29. Apache Kafka的缺陷
    - 仅提供了较少的核心功能
    - 可能出现重复消费消息，无法保证消息刚好出现一次。目前只能保证至少一次
    - 没有完整的监控工具集
30. 解释Apache Kafka用例（经常使用的场景）
    - 指标收集。可以使用Kafka进行操作监测数据。此外，为了生成操作数据的集中提要，它涉及到从分布式应用程序聚合统计信息
    - 日志聚合。从组织中的多个服务收集日志
    - 流处理.在流处理过程中，Kafka的强耐久性非常有用
    - ![](https://raw.githubusercontent.com/roperluo32/images/master/image20191227073909.png)
31. Kafka提供的保证是什么
    - 生产者向特定主题分区发送的消息的顺序相同。
    - 消费者实例按照它们存储在日志中的顺序查看记录。
    - 即使不丢失任何提交给日志的记录，我们也可以容忍最多N-1个服务器故障




## API -- 生产者&消费者&流&connector
1. Kafka 的消费者如何做消息去重
    - 消费端建立去重表
    - 将消息的唯一标识保存到外部介质中，每次消费处理时判断是否处理过；
7. Kafka如何解决数据堆积
    - 根据业务情况去回答，如果数据允许丢失，那么就创建N个消费者去把堆积的数据读取出来丢掉
    - 如果数据不能容忍丢失，那么只能扩容10倍的消费者和topic分区，将队列中的消息读入10倍的分区中去消费。相当于以线上10倍的速度去消费掉队列中的消息。
8. 如何用kafka保证消息的有序性
    - 相同key的消息放入同一个queue（topic分区）中，同时保证相同key的消息只会有一个线程去生产&消费 



## 分区&复制
1. controller控制器的作用
    - 控制器其实就是一个broker，只不过它除了具有一般broker 的功能之外，还负责分区首领的选举
2. controller控制器的选举
    - 集群里第一个启动broker通过在Zookeeper里创建一个临时节点/controller 让自己成为控制器。其broker在启动时也会尝试创建这个节点，不过它们会收到一个“节点已存在”的异常，然后“意识”到控制器节点已存在，也就是说集群里已经有一个控制器了
3. 解释领导者和追随者的概念
    - 在Kafka的每个分区中，都有一个服务器充当领导者，0到多个服务器充当追随者的角色
4. 追随者是怎么复制领导者的？
    - 为了与首领保持同步，跟随者向首领发送获取数据的请求，这种请求与消费者为了读取消息而发送的请求是一样的。首领将响应消息发给跟随者。请求消息里包含了跟随者想要获取消息的偏移量，而且这些偏移量总是有序的
    - 跟随者的正常不活跃时间或在成为不同步副本之前的时间是通过 replica.lag.time.max.ms参数来配置的。这个时间间隔直接影响着首领选举期间的客户端行为和数据保留机制
4. 怎么选举分区首领的？
    - 控制器遍历这些所有副本分区，并确定谁应该成为新首领（简单来说就是分区副本列表里的下一个副本）然后向所有包含新首领或现有跟随broker发送请求。该请求消息包含了谁是新首领以及谁是分区跟随者的信息随后，新首领开始处理来自生产者和消费者的请求，而跟随者开始从新首领那里复制消息
5. 是什么确保了Kafka中服务器的负载平衡
    - 生产者的负载均衡。对于同一个Topic的不同Partition，Kafka会尽力将这些Partition分布到不同的Broker服务器上，这种均衡策略实际上是基于Zookeeper实现的。在一个Broker启动时，会首先完成Broker的注册过程，并注册一些诸如“有哪些可订阅的Topic”之类的元数据信息
    - 消费者的负载均衡。Kafka具有消费分组的概念，某个Topic的某个partition只能由一个Consumer group中的一个Consmer消费。但如果两个Consmer不在同一个Consumer group，那么他们是可以同时消费某Topic的同一个partition的。
对于某些低级别的API，Consumer消费时必须制定topic和partition，这显然不是一种很好的均衡策略。基于高级别的API，Consumer消费时只需制定topic，借助zookeeper可以根据partition的数量和consumer的数量做到均衡的动态配置。
     - [Kafka集群生产/消费的负载均衡](https://blog.csdn.net/cjf_wei/article/details/57121845)

6. 副本和ISR扮演什么角色
     - 复制日志的节点列表就是副本。对于特定的分区，无论他们是否扮演领导者的角色，他们都是如此
     - ISR指的是同步副本。在定义ISR时，它是一组与领导者同步的消息副本
7. 如果副本长时间不在ISR中，这意味着什么？
     - 简单地说，这意味着跟随者不能像领导者收集数据那样快速地获取数据
8. 什么是Kafka中的地域复制
     - 对于我们的集群，Kafka MirrorMaker提供地理复制。基本上，消息是通过MirrorMaker跨多个数据中心或云区域复制的。因此，它可以在主动/被动场景中用于备份和恢复；也可以将数据放在离用户更近的位置，或者支持数据位置要求
9. 

## 存储
1. 在Kafka集群中保留期的目的是什么
    - 保留期限保留了Kafka群集中的所有已发布记录。它不会检查它们是否已被消耗。此外，可以通过使用保留期的配置设置来丢弃记录。而且，它可以释放一些空间
8. kafka消息的存储机制


## zookeeper   
1. 启动Kafka服务器的过程是什么
    - 初始化ZooKeeper服务器是非常重要的一步，因为Kafka使用ZooKeeper，所以启动Kafka服务器的过程是：
    - 要启动ZooKeeper服务器：>bin/zooKeeper-server-start.sh config/zooKeeper.properties
    - 启动Kafka服务器：>bin/kafka-server-start.sh config/server.properties
2. kafka中的 zookeeper 起到什么作用，可以不用zookeeper么
     - zookeeper 是一个分布式的协调组件，早期版本的kafka用zk做meta信息存储，consumer的消费状态，group的管理以及 offset的值。考虑到zk本身的一些因素以及整个架构较大概率存在单点问题，新版本中逐渐弱化了zookeeper的作用。新的consumer使用了kafka内部的group coordination协议，也减少了对zookeeper的依赖，
     - 但是broker依然依赖于ZK，zookeeper 在kafka中还用来选举controller 和 检测broker是否存活等等

## 其它内部原理性问题
1. 有哪些主从选举