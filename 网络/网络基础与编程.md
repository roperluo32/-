[TOC]
## TCP三次握手和四次挥手
- TCP三次握手过程
![](http://images-1251273400.cosgz.myqcloud.com/2b7a6de6-58e4-43a5-82b1-ad06b81b06f0.jpg)
- TCP的四次挥手
![](http://images-1251273400.cosgz.myqcloud.com/df903199-8c0a-4aeb-b56a-0c5372f8c9b6.jpg)

- 四次挥手中，TIME-WAIT状态是在哪一步？
  - 主动发起close的一方，收到被动方的FIN后，主动方就会进入TIME_WAIT状态

- TIME-WAIT状态下的等待时间是多少？为何是2MSL?
  - MSL。即为Max Segment Lifetime, 一个包在网络上生存的最长时间，默认是120s
  - 为何是2MSL，需要确认主动方重复发送的ACK和被动方重复发送的FIN在网络上彻底消亡


- 什么时候会收到RST报文段
  - RST标示复位、用来异常的关闭连接。
    - 发送RST包关闭连接时，不必等缓冲区的包都发出去，直接就丢弃缓冲区中的包，发送RST
    - 而接收端收到RST包后，也不必发送ACK包来确认
  - 没有监听的端口。建立连接的SYN到达某端口，但是该端口上没有正在 监听的服务
  - TCP收到了一个根本不存在的连接上的分节。比如客户端在服务端已经关闭掉socket之后，仍然在发送数据。这时服务端会产生RST
  - 请求超时。 使用setsockopt的SO_RCVTIMEO选项设置recv的超时时间。接收数据超时时，会发送RST包

- 服务器大量处于TIME_WAIT状态，可能的原因，造成什么影响，怎么解决
  - 原因：服务器端主动发出FIN来断开连接
  - 影响：过多的TIME_WAIT造成端口和文件描述符被大量占用，无法建立新的连接
  - 解决：开启timewait的快速回收和重用
  ```
  net.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；
  net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
  net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。
  net.ipv4.tcp_fin_timeout 修改系默认的 TIMEOUT 时间
  ```
  - 如果以上配置调优后性能还不理想，可继续修改一下配置
  ```
  net.ipv4.tcp_keepalive_time = 1200 
  #表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20 分钟。
  net.ipv4.ip_local_port_range = 1024 65000 
  #表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。
  net.ipv4.tcp_max_syn_backlog = 8192 
  #表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络  连接数。
  net.ipv4.tcp_max_tw_buckets = 5000 
  #表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接 字将立刻被清除并打印警告信息。
  默认为180000，改为5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减 少TIME_WAIT套接字数量，但是对于 Squid，效果却不大。此项参数可以控制  TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。
  ```
- 为什么timewait（两点）
  - 可靠地实现TCP全双工连接的终止。如果服务端没有收到ACK，保持timewait状态可以重传ACK，确保被动端收到以可靠终止连接。
  - 确保老的重复分节在网络中消逝（最大需要等待2MSL）

- 服务器大量处于close_wait的原因，以及怎么处理
  - 原因：服务端忘记关闭socket
  - 处理：检查程序遗漏关闭socket的地方


- UDP怎么实现TCP的拥塞控制？
- UDP可靠传输
  - UDP已经是不可靠的连接，那就要在应用层自己实现一些保障可靠传输的机制
  - 要使用UDP来构建可靠的面向连接的数据传输，就要实现类似于TCP协议的超时重传（定时器），有序接受 （添加包序号），有序接受 （添加包序号），滑动窗口流量控制等机制
  - UDT。基于UDP的数据传输协议（UDP-based Data Transfer Protocol，简称UDT）是一种互联网数据传输协议
  - QUIC。QUIC是Google实现的一种可靠UDP传输协议，并且已经被选择作为HTTP/3的基础
  ![](http://images-1251273400.cosgz.myqcloud.com/20201017222506.png)
  - [《基于UDP的数据传输协议（UDP-based Data Transfer Protocol，简称UDT）是一种互联网数据传输协议》](https://blog.csdn.net/ls5718/article/details/52141571)
  - [《可靠UDP传输协议总结》](https://zhuanlan.zhihu.com/p/68466363)
  
- QUIC
  - 为什么要使用QUIC
    - UDP比TCP传输速度快，QUIC是基于UDP实现的可靠协议
    - 其次TCP是系统内核实现的，如果升级TCP协议，就得让用户升级系统，这个的门槛比较高，而QUIC在UPD基础上由客户端自由发挥，只要有服务器能对接就可以
    ![](http://images-1251273400.cosgz.myqcloud.com/20201017224411.png)
  - 连接建立延时低。QUIC只需要一次往返就能建立HTTPS连接
  - 改进的拥塞控制
    - TCP 的拥塞控制实际上包含了四个算法：慢启动，拥塞避免，快速重传，快速恢复
    - QUIC 协议当前默认使用了 TCP 协议的 Cubic 拥塞控制算法，同时也支持 CubicBytes, Reno, RenoBytes, BBR, PCC 等拥塞控制算法
  - QUIC的NACK比TCP的延迟确认机制高效
  - FEC前向纠正拥塞控制。FEC是Forward Error Correction前向错误纠正的意思，就是通过多发一些冗余的包，当有些包丢失时，可以通过冗余的包恢复出来，而不用重传
  - 切换网络操持连接。QUIC使用一个ID来标志连接，即使切换网络也可以使用之前的建立连接的数据如交换的密钥，而不用再重新HTTPS握手
  - [《浅谈QUIC协议原理与性能分析及部署方案》](https://juejin.im/post/6844904182361636878)

## TCP底层原理
- TCP中的流量控制与拥塞控制
  - 拥塞控制。拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况；常用的方法就是：（ 1 ）慢开始、拥塞避免（ 2 ）快重传、快恢复
  - 流量控制。流量控制是作用于接收者的，它是控制发送者的发送速度从而使接收者来得及接收，防止分组丢失的

- 慢开始，拥塞避免算法
  - 初始时把拥塞窗口cwnd设为1（慢开始），然后每次来回只要没有出现超时，cwnd就翻倍
  - 当cwnd超过ssthresh门限值，就转为拥塞避免算法，即每次来回只要没超时，cwnd就+1
  - 如果出现了超时，那么cwnd就立即变成1，同时ssthresh门限值就减半，然后开始执行慢开始
![](http://images-1251273400.cosgz.myqcloud.com/20201017205801.png)
  - [《TCP流量控制、拥塞控制》](https://zhuanlan.zhihu.com/p/37379780)

- 快重传，快恢复算法
  - 快重传。快重传要求接收方在收到一个失序的报文段后就立即发出重复确认，而不要等到自己发送数据时捎带确认；发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期
  ![](http://images-1251273400.cosgz.myqcloud.com/20201017211257.png)
  - 快恢复。当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半。但是cwnd不设为1，而是设置为ssthresh减半后的值，然后执行拥塞避免算法，使cwnd缓慢增大。这样做是因为考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞
  ![](http://images-1251273400.cosgz.myqcloud.com/20201017211458.png)


- TCP连接的两方，某一方突然断网了，怎么办，嫌keepalive的时间太长的怎么办？
  - TCP还设有一个保活计时器（keepalive)，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。
  - 以通过设置套接字选项将时间设置短一点
  ```
  setsockopt(s, SOL_SOCKET, SO_KEEPALIVE, &optval, sizeof(optval))
  ```

- 网线断开会发生什么（超时）哪一端会先断开（？）
  - 发送包（心跳包或者数据包）并检测到超时的一方会先感知到断开

- 说说MTU，跟着扩展到网络层分片
  - 最大传输单元（Maximum Transmission Unit，MTU）用来通知对方所能接受数据服务单元的最大尺寸，说明发送方能够接受的有效载荷大小
  - 以太网和802.3对数据帧的长度都有一个限制，其最大值分别是1500字节和1492字节
  - 如果IP层有一个数据报要传，而且数据帧的长度比链路层的MTU还大，那么IP层就需要进行分片( fragmentation)，即把数据报分成干片，这样每一片就都小于MTU

- 说一说滑动窗口
  - 使用滑动窗口保证包的顺序性，超时重传，累积ACK回复等特性，来保证TCP的可靠性
  - 下图是发送端的滑动窗口。分为四类：已收到ACK确认的；已发送但没收到ACK的；未发送但允许发送的；未发送但不允许发送的（接收方流量控制不允许发送）
  ![](http://images-1251273400.cosgz.myqcloud.com/20201018095127.png)

  - [《TCP-IP详解：滑动窗口》](https://blog.csdn.net/wdscq1234/article/details/52444277)
- 当滑动窗口为0的时候是因为什么，是对端发生了什么？问：是阻塞在那一层
  - 本质上是因为 TCP 接收方的接收缓存已经满了，没有空间再接收数据
  - 死锁。当接收方滑动窗口变零后，也就是接收到发送方滑动窗口里的全部数据后，会将最后一个字节序号+1作为确认号返回发送方，发送方的滑动窗口此时变零，引起死锁（因为窗口为0，没东西发了，接收方没东西收也不会反馈）
  -  Zero Probe 报文（零窗口探测报文）。发送方需要进行0窗口探测，定时探测接收方的窗口是否腾出了位置

- 滑动窗口为什么是字节为单位滑动的？
  - TCP是面向字节流的

- 介绍一下拥塞控制，丢包时为什么阈值会减半
  - 降低拥塞窗口cwnd增大的速度

- TCP已经有了保活为什么还要有心跳包
  - keepalive是操作系统协议栈层次的连接检查，并不能确保上层应用还是可用的（比如程序死锁，或者过载都会导致应用不可用）
  - keepalive包的优先级低于数据重传包，因此keepalive机制会有比较大的延迟
  - [《TCP中已有SO_KEEPALIVE选项，为什么还要在应用层加入心跳包机制》](https://blog.csdn.net/gettogetto/article/details/76736371)

- tcp黏包问题
  - TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾
    - 发送端需要等缓冲区满才发送出去，造成粘包
    - 接收方不及时接收缓冲区的包，造成多个包接收
  - 解决方案。在应用层协议中，最常见的两种解决方案就是基于长度或者基于终结符（Delimiter）
    - 发送固定长度的消息
    - 把消息的尺寸与消息一块发送
    - 使用特殊标记来区分消息间隔
  - [《为什么 TCP 协议有粘包问题》](https://draveness.me/whys-the-design-tcp-message-frame/)
  - [《TCP粘包问题分析和解决》](https://blog.csdn.net/tiandijun/article/details/41961785)

- TCP数据包传到IP层会不会发生分包
  - 不会
  - TCP 协议为了保证可靠性，会通过 IP 协议的 MTU 计算出 MSS 并根据 MSS 分段避免 IP 协议对数据包进行分片。因为 IP 协议对数据包的分片对上层是透明的，如果协议不根据 MTU 做一些限制，那么 IP 协议的分片会导致部分数据包失去传输层协议头，一旦数据包发生丢失就只能丢弃全部数据。
  ![](http://images-1251273400.cosgz.myqcloud.com/20201018110720.png)
  - 补充：IP 协议拆分数据是因为物理设备的限制，一次能够传输的数据由路径上 MTU 最小的设备决定，一旦 IP 协议传输的数据包超过 MTU 的限制就会发生丢包，所以我们需要通过路径 MTU 发现获取传输路径上的 MTU 限制
  - [《为什么 TCP/IP 协议会拆分数据》](https://draveness.me/whys-the-design-tcp-segment-ip-packet/)

- TCP MSS（最大分段大小 Maximum segment size）概念和协商过程
  - TCP在三次握手建立连接过程中，会在SYN报文中使用MSS（Maximum Segment Size）选项功能，协商交互双方能够接收的最大段长MSS值
  - MSS是传输层TCP协议范畴内的概念，顾名思义，其标识TCP能够承载的最大的应用数据段长度，因此，MSS=MTU-20字节TCP报头-20字节IP报头，那么在以太网环境下，MSS值一般就是1500-20-20=1460字节
  - 客户端与服务器端分别根据自己发包接口的MTU值计算出相应MSS值，并通过SYN报文告知对方

- - TCP里多大的数据量传输要进行封装？
  - 超过MSS大小的数据量就需要进行拆分和独立封装，以避免数据包要整个重传（IP 协议对数据包的分片对上层是透明的，如果协议不根据 MTU 做一些限制，那么 IP 协议的分片会导致部分数据包失去传输层协议头，一旦数据包发生丢失就只能丢弃全部数据）

- tcp超时重传具体多久
  - 超时重传时间RTO。超时重传的时间设置的要比往返时间（RTT）要长一些
  - RTT的计算。第一次测量RTT时，RTTS就取所测量到的RTT样本值，即RTTS=RTT样本。以后每次测量到一个新的RTT样本，就按下面的公式重新计算一次RTTS：
  ```
  新RTTS=(1−α)×旧RTTS+α×RTT
  在上面的公式中a的取值为：0≤α≤1，RFC推荐的α值为1/8，即0.125
  ```
  - 超时重传时间 = 加权平均往返时间RTTs + 一点点时间
  - 一点点时间RTTD的计算
  ```
    当第一次测量RTTD 时，RTTD 值取为测量到的RTT样本值的一半，公式为：RTTD=RTT/2
    在以后的每次测量RTTD中，使用下面的公式加权平均的RTTD，这样得到的就是更为平滑的RTTD：新RTTD=(1−β)×旧RTTD+β×|RTTS−RTT|
    通常β是一个小于1的数，RFC推荐β的值为1/4，即0.25
  ```
  - [《tcp可靠传输——超时重传时间》](https://blog.csdn.net/qq_35733751/article/details/80173022)

- IP，TCP，UDP头部字节大小多少？
  - ip头部定义。20个字节
  ![](http://images-1251273400.cosgz.myqcloud.com/20201018111505.png)
  - TCP头部。20个字节
  ![](http://images-1251273400.cosgz.myqcloud.com/20201018111531.png)
  - UDP头部。8个字节
  ![](http://images-1251273400.cosgz.myqcloud.com/20201018111550.png)
  - [《ip头、tcp头、udp头详解及定义，结合Wireshark抓包看实际情况》](https://www.cnblogs.com/shenpengyan/p/5912567.html)

- Nagle算法
  - Nagle算法主要是避免发送小的数据包，要求TCP连接上最多只能有一个未被确认的小分组，在该分组的确认到达之前不能发送其他的小分组
  - Nagle 算法是一种通过减少数据包的方式提高 TCP 传输性能的算法4。因为网络 带宽有限，它不会将小的数据块直接发送到目的主机，而是会在本地缓冲区中等待更多待发送的数据，这种批量发送数据的策略虽然会影响实时性和网络延迟，但是能够降低网络拥堵的可能性并减少额外开销
  - ![](http://images-1251273400.cosgz.myqcloud.com/20201018103005.png)

## 网络编程
- 讲一下poll和epoll和select的区别
  - select
    - 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
    - select支持的文件描述符数量太小，默认是1024
    - 底层实现需要不断轮询所有fd集合，直到设备就绪
  - poll
    - 每次调用也有从用户态拷贝到内核态的开销
    - fd采用链表存储，因此没有fd上限
    - - 底层实现需要不断轮询所有fd集合，直到设备就绪
  - epoll
    - 新增fd知会在epoll_ctl时拷贝一次
    - 没有fd上限
    - 底层实现只需要不断判断就绪链表是否为空就行
  ![](http://images-1251273400.cosgz.myqcloud.com/20201018114540.png)
    - [《select、poll、epoll之间的区别》](https://www.cnblogs.com/aspirant/p/9166944.html )


- epoll的机制，什么时候用ET
  - LT：水平触发，效率会低于ET触发，尤其在大并发，大流量的情况下。但是LT对代码编写要求比较低，不容易出现问题。LT模式服务编写上的表现是：只要有数据没有被获取，内核就不断通知你，因此不用担心事件丢失的情况。
  - ET：边缘触发，效率非常高，在并发，大流量的情况下，会比LT少很多epoll的系统调用，因此效率高。但是对编程要求高，需要细致的处理每个请求，否则容易发生丢失事件的情况

- 使用Linux epoll模型，水平（LT）触发模式，当socket可写时，会不停的触发socket可写的事件，如何处理
  - 方法一：需要向socket写数据的时候才把socket加入epoll，等待可写事件。接受到可写事件后，调用write或者send发送数据。当所有数据都写完后，把socket移出epoll。缺点：即使发送很少的数据，也要把socket加入epoll，写完后在移出epoll，有一定操作代价
  - 方法二：开始不把socket加入epoll，需要向socket写数据的时候，直接调用write或者send发送数据。如果返回EAGAIN，把socket加入epoll，在epoll的驱动下写数据，全部数据发送完毕后，再移出epoll
  - [《彻底学会使用epoll(六)——关于ET的若干问题总结》](https://yq.aliyun.com/articles/412820)

- epoll水平触发和边沿触发，底层原理
  - 内核初始化epoll时，会开辟一块内核高速cache区，用于安置我们监听的socket，这些socket会以红黑树的形式保存在内核的cache里，以支持快速的查找，插入，删除．同时，建立了一盒list链表，用于存储准备就绪的事件
  - 当一个socket句柄上有事件时，内核会把该句柄插入上面所说的准备就绪list链表，这时我们调用epoll_wait，会把准备就绪的socket拷贝到用户态内存，然后清空准备就绪list链表，最后，epoll_wait干了件事，就是检查这些socket，如果不是ET模式（就是LT模式的句柄了），并且这些socket上确实有未处理的事件时，又把该句柄放回到刚刚清空的准备就绪链表了。所以，非ET的句柄，只要它上面还有事件，epoll_wait每次都会返回。而ET模式的句柄，除非有新中断到，即使socket上的事件没有处理完，也是不会次次从epoll_wait返回的
  - [《谈谈epoll实现原理》](http://luodw.cc/2016/01/24/epoll)


- epoll_wait的最后一个参数是什么意思，如果设置为0会怎样
  - 参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个 maxevents的值不能大于创建epoll_create()时的size
  - 参数timeout是超时时间（毫秒) ,是一个绝对时间。0会立即返回，-1将不确定，也有说法说是永久阻塞。该函数返回需要处理的事件数目，如返回0表示已超时
  ```c++
  int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
  ```

- 惊群问题
  - accept惊群。主进程创建了监听套接字，然后创建了多个子进程去listen。当有connect请求时，多个子进程都会被唤醒，但只会有一个进程最终处理请求
    - 在linux2.6版本以后，linux内核已经解决了accept（）函数的“惊群”现象，大概的处理方式就是，当内核接收到一个客户连接后，只会唤醒等待队列上的第一个进程（线程）,所以如果服务器采用accept阻塞调用方式，在最新的linux系统中已经没有“惊群效应”了
  - epoll惊群。如果多个进程/线程阻塞在监听同一个监听socket fd的epoll_wait上，当有一个新的连接到来时，所有的进程都会被唤醒
  - 线程惊群。pthread_cond_broadcast()在资源准备好以后，或者你再编写程序的时候设置的某个事件满足时它会唤醒队列上的所有线程去处理这个事件，但是只有一个线程会真正的获得事件的“控制权”
  - [《Linux惊群效应详解》](https://blog.csdn.net/lyztyycode/article/details/78648798)
  - [《什么是惊群，如何有效避免惊群》](https://www.zhihu.com/question/22756773)

- listen函数的backlog参数是什么意思；backlog的作用，编程中应该设置为多大
  - linux内核中会维护两个队列： 
    - 1）未完成队列：接收到一个SYN建立连接请求，处于SYN_RCVD状态 
    - 2）已完成队列：已完成TCP三次握手过程，处于ESTABLISHED状态 
  - 当有一个SYN到来请求建立连接时，就在未完成队列中新建一项。当三次握手过程完成后，就将套接口从未完成队列移动到已完成队列。 
  - backlog曾被定义为两个队列的总和的最大值，也曾将backlog的1.5倍作为未完成队列的最大长度，一般将backlog指定为5

- 客户端是是否可以使用bind
  - 服务器和客户端都可以bind，bind并不是服务器的专利
  - 客户端进程bind端口：由进程选择一个端口去连服务器

- 网络编程的函数调用套路，客户端服务器端（还说了一些连接队列）
  ![](http://images-1251273400.cosgz.myqcloud.com/20201018213107.png)

- accept函数在面对超过数十个连接过来的时候怎么处理，是一个个处理吗？还是一起处理
  - accept调用将消费积压在 accept 队列里的连接
  - [《TCP的SYN队列和Accept队列》](https://network.51cto.com/art/201911/606094.htm)


## Reactor与IO模型
- 你觉得主线程用来Accept好吗？为什么好？我用100个线程来accept不一样吗？你觉得Reactor模式好在哪？

- IO模型有哪些

- 用的最多的应该算IO多路复用模型，讲讲它的优缺点

- 介绍下libev库（基于事件驱动的高性能库） 什么是reactor模型

- Reactor反应堆模式
  - Reactor模式是处理并发I/O常见的一种模式，用于同步I/O，其中心思想是将所有要处理的I/O事件注册到一个中心I/O多路复用器上，同时主线程阻塞在多路复用器上，一旦有I/O事件到来或是准备就绪，多路复用器将返回并将相应I/O事件分发到对应的处理器中
  - [《Reactor 反应堆设计模式》](https://juejin.im/entry/6844904073251012622)


## 网络基础

- 数据包从网卡到网卡要经历那些内存拷贝？

- 七层、五层结构
  ![](http://images-1251273400.cosgz.myqcloud.com/20201019223209.png)
  
- 讲一下ARP协议
  -  ARP 协议的用途是从网络层使用的 IP地址 中解析出在数据链路层使用的硬件地
  ![](http://images-1251273400.cosgz.myqcloud.com/20201019223403.png)
  - 由于 IP 协议 中使用了 ARP 协议，因此通常将 ARP 协议归为网络层协议
  - [《ARP协议详解》](https://juejin.im/entry/6844903666445451272)

- ARP欺诈
  - 攻击者发送假的ARP数据包到网上，尤其是送到网关上。其目的是要让送至特定的IP地址的流量被错误送到攻击者所取代的地方

- IP包头中的TTL是什么意思？
  - TTL(Time-To-Live)的作用是限制数据包在网络中存在的时间，防止数据包不断的在IP互联网络上循环

- 说说你看过的网络库
  - libevent, libev, boost asio
  - [《我对开源C++网络库简单应用总结》](https://www.cnblogs.com/lidabo/p/4062847.html)

- socks5协议流程
  - socks5协议是一款广泛使用的代理协议，它在使用TCP/IP协议通讯的前端机器和服务器机器之间扮演一个中介角色，使得内部网中的前端机器变得能够访问Internet网中的服务器，或者使通讯更加安全
  - 连接过程
    - 1.客户端发送认证协商
    - 2.代理服务器就认证协商进行回复
    - 3.客户端发送希望连接的目标信息
    - 4.代理服务器就连接信息进行确认或拒绝
    - 5.代理服务器连接目标并 pipe 到客户端
  ![](http://images-1251273400.cosgz.myqcloud.com/20201019224612.png)

- traceroute 命令的原理
    - 用 IP 生存时间 (TTL) 字段和 ICMP 错误消息来确定从一个主机到网络上其他主机的路由
    - 首先，tracert送出一个TTL是1的IP 数据包到目的地，当路径上的第一个路由器收到这个数据包时，它将TTL减1。此时，TTL变为0，所以该路由器会将此数据包丢掉，并送回一个「ICMP time exceeded」消息。tracert 收到这个消息后，便知道这个路由器存在于这个路径上，接着tracert 再送出另一个TTL是2 的数据包，发现第2 个路由器。。
    - [《Tracert(traceroute)&Ping 工作原理分析》](https://blog.csdn.net/qq_30135181/article/details/50992151)

- ping 工作过程分析
    - 发送一个ICMP echo请求消息给目的地并报告是否收到所希望的ICMP echo （ICMP回声应答）
    - 利用网络上机器IP地址的唯一性，给目标IP地址发送一个数据包，再要求对方返回一个同样大小的数据包来确定两台网络机器是否连接相通，时延是多少
    

## 网络加密
- SSL的原理和过程
  - 四次握手过程
  - 主要交换三个信息
    - 数字证书：该证书包含了公钥等信息，一般是由服务器发给客户端，接收方通过验证这个证书是不是由信赖的CA签发，或者与本地的证书相对比，来判断证书是否可信；假如需要双向验证，则服务器和客户端都需要发送数字证书给对方验证；
    - 三个随机数：这三个随机数构成了后续通信过程中用来对数据进行对称加密解密的“对话密钥”。首先客户端先发第一个随机数N1，然后服务器回了第二个随机数N2（这个过程同时把之前提到的证书发给客户端），这两个随机数都是明文的；而第三个随机数N3（这个随机数被称为Premaster secret），客户端用数字证书的公钥进行非对称加密，发给服务器；而服务器用只有自己知道的私钥来解密，获取第三个随机数。这样，服务端和客户端都有了三个随机数N1+N2+N3，然后两端就使用这三个随机数来生成“对话密钥”，在此之后的通信都是使用这个“对话密钥”来进行对称加密解密。因为这个过程中，服务端的私钥只用来解密第三个随机数，从来没有在网络中传输过，这样的话，只要私钥没有被泄露，那么数据就是安全的。
    - 加密通信协议：就是双方商量使用哪一种加密方式，假如两者支持的加密方式不匹配，则无法进行通信
  ![](http://images-1251273400.cosgz.myqcloud.com/20201019225040.png)
  - [《SSL/TLS协议运行机制的概述》](https://www.ruanyifeng.com/blog/2014/02/ssl_tls.html)

- 公钥私钥介绍下
  - RSA基于大质数难以分解

- 非对称加密算法流程
  - 乙方生成两把密钥（公钥和私钥）。公钥是公开的，任何人都可以获得，私钥则是保密的。
  - 甲方获取乙方的公钥，然后用它对信息加密。
  - 乙方得到加密后的信息，用私钥解密
  - [《RSA算法原理》](https://www.ruanyifeng.com/blog/2013/06/rsa_algorithm_part_one.html)
- 常用签名算法；
  - MD5、SHA-1、SHA-256比较
    - 速度：MD5>SHA-1>SHA-256
    - 安全性：MD5<SHA-1<<SHA-256
    - 哈希值长度：MD5(128bit)<SHA-1(160bit)<SHA-256(256bit)
  - [《常用的签名算法》](https://www.jianshu.com/p/9abc781fc665)

## 网络应用题
- LOL，吃鸡这种游戏的网络协议怎么设计？tcp会有哪些地方可能造成延时高
  - [《游戏开发经验谈 (二)：对战类全球服游戏的设计与实现》](https://ruby-china.org/topics/37332)

- 花生壳内网穿透原理
  - NAT穿透，即在计算机是局域网内的时候，外网与内网的计算机的节点进行连接时所需要的连接通信
  - 内网穿透利用NAT可以让内网机器访问外网的特点，让在NAT之后的节点主动访问一个拥有公网IP地址的服务器，并由中间服务器搭桥，打通经过该服务器从其他主机到NAT之后节点的隧道
  ![](http://images-1251273400.cosgz.myqcloud.com/20201019231247.png)
